{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r path/to/requirements.txt # Install all the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from tensorflow.keras.applications import resnet, ResNet50,VGG16,ResNet101, VGG19\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import imutils\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Validation, and Test Sub-directory setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Introduction</h3>\n",
    "The dataset we are analyzing in this notebook pertains to MRI (Magnetic Resonance Imaging) scans of brain tumors. MRI is a medical imaging technique used to visualize internal structures of the body in detail. In the context of neurology, MRI scans play a crucial role in the diagnosis and monitoring of brain tumors.\n",
    "\n",
    "<h3>Source</h3>\n",
    "The data has been sourced from Kaggle, a platform that hosts a plethora of datasets for various machine learning and data analysis tasks. This specific dataset, titled \"Brain Tumor MRI Dataset,\" has been provided by a user named Masoud Nickparvar. The dataset can be accessed via the following link:\n",
    "\n",
    "ðŸ§  <a href='https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset'>Brain Tumor MRI Dataset on Kaggle</a>\n",
    "\n",
    "The dataset is expected to comprise images of MRI scans, some of which are likely to show the presence of brain tumors while others might be normal scans. Our goal in this notebook is to dive deep into the data, understand its structure, and potentially derive insights or build predictive models based on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hello Cameron!</h1>\n",
    "<a href='mattbarty.com'>click me</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base directory\n",
    "src_dir = './data/'\n",
    "\n",
    "# subdirectories\n",
    "train_dir = os.path.join(src_dir, 'Training')\n",
    "test_dir = os.path.join(src_dir, 'Testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref: [finding-extreme-contours](https://pyimagesearch.com/2016/04/11/finding-extreme-points-in-contours-with-opencv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all subdirectories paths (each one is a class label)\n",
    "categories = ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
    "\n",
    "# Specify the number of columns for your plot\n",
    "ncols = 8\n",
    "\n",
    "# Set up matplotlib fig\n",
    "fig, ax = plt.subplots(len(categories), ncols, figsize=(20, 10))\n",
    "\n",
    "# For each subdirectory, select random images\n",
    "for i, subdir in enumerate(categories):\n",
    "    subdir_path = os.path.join(train_dir, subdir) # Get full subdir path\n",
    "    subdir_images = os.listdir(subdir_path) # Get list of dir contents\n",
    "    random_image_names = random.sample(subdir_images, ncols) # Get a sample of dir content\n",
    "    img_paths = [os.path.join(subdir_path, img_name) for img_name in random_image_names] # Append path to each sample image\n",
    "    \n",
    "    for j, img_path in enumerate(img_paths):\n",
    "        # Set up subplot; subplot indices start at 1\n",
    "        sp = ax[i, j]\n",
    "        if j == 0:\n",
    "            sp.set_title(os.path.basename(subdir), fontsize=30)  # set title to the first image of each row\n",
    "        sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "        img = mpimg.imread(img_path)\n",
    "        sp.imshow(img) # Show random image\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_transformations(img, debug_mode=False):\n",
    "    \"\"\"\n",
    "    Applies transformations to the image and plots each step\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Apply threshold\n",
    "    thresh = cv2.threshold(gray_blurred, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Apply erosion and dilation\n",
    "    thresh_eroded = cv2.erode(thresh, None, iterations=2)\n",
    "    thresh_dilated = cv2.dilate(thresh_eroded, None, iterations=2)\n",
    "\n",
    "    # Find contours\n",
    "    cnts = cv2.findContours(thresh_dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # Find the largest contour\n",
    "    c = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "    # Find the extreme points\n",
    "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "    extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "    extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\n",
    "    # Crop the image\n",
    "    PIXEL_PADDING = 0  # Adjust this value to your needs\n",
    "    new_img = img[extTop[1]-PIXEL_PADDING:extBot[1]+PIXEL_PADDING, extLeft[0]-PIXEL_PADDING:extRight[0]+PIXEL_PADDING].copy()\n",
    "\n",
    "    # If debug mode is enabled, plot the images\n",
    "    if debug_mode:\n",
    "        cnt_img = img.copy()\n",
    "\n",
    "        # draw the outline of the object, then draw each of the\n",
    "        # extreme points, where the left-most is red, right-most\n",
    "        # is green, top-most is blue, and bottom-most is teal\n",
    "        cv2.drawContours(cnt_img, [c], -1, (0, 255, 255), 2)\n",
    "        cv2.circle(cnt_img, extLeft, 8, (0, 0, 255), -1)\n",
    "        cv2.circle(cnt_img, extRight, 8, (0, 255, 0), -1)\n",
    "        cv2.circle(cnt_img, extTop, 8, (255, 0, 0), -1)\n",
    "        cv2.circle(cnt_img, extBot, 8, (255, 255, 0), -1)\n",
    "\n",
    "        # Plot images\n",
    "        fig, axs = plt.subplots(1, 7, figsize=(20, 20))\n",
    "        axs[0].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        axs[0].set_title('Original Image')\n",
    "        axs[1].imshow(gray, cmap='gray')\n",
    "        axs[1].set_title('Grayscale Image')\n",
    "        axs[2].imshow(gray_blurred, cmap='gray')\n",
    "        axs[2].set_title('Blurred Image')\n",
    "        axs[3].imshow(thresh, cmap='gray')\n",
    "        axs[3].set_title('Thresholded Image')\n",
    "        axs[4].imshow(thresh_dilated, cmap='gray')\n",
    "        axs[4].set_title('Dilated Image')\n",
    "        axs[5].imshow(cv2.cvtColor(cnt_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[5].set_title('Contour Image')\n",
    "        axs[6].imshow(cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[6].set_title('Cropped Image')\n",
    "        \n",
    "        # # -- Save images if you'd like\n",
    "        # plt.imsave('1-original.png', cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        # plt.imsave('2-grayscale.png', gray, cmap='gray')\n",
    "        # plt.imsave('3-blurred.png', gray_blurred, cmap='gray')\n",
    "        # plt.imsave('4-thresholded.png', thresh, cmap='gray')\n",
    "        # plt.imsave('5-dilated.png', thresh_dilated, cmap='gray')\n",
    "        # plt.imsave('6-contour.png', cv2.cvtColor(cnt_img, cv2.COLOR_BGR2RGB))\n",
    "        # plt.imsave('7-cropped.png', cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.axis('off')\n",
    "\n",
    "    # If debug mode is not enabled, return the cropped image\n",
    "    else:\n",
    "        return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first image name from 'yes' directory\n",
    "first_image_name = random.choice(os.listdir(os.path.join(src_dir, 'Training', 'glioma_tumor')))\n",
    "\n",
    "# Get full path of the image\n",
    "first_image_path = os.path.join(src_dir, 'Training', 'glioma_tumor', first_image_name)\n",
    "\n",
    "# Now read the image\n",
    "img = cv2.imread(first_image_path)\n",
    "\n",
    "# Visualize the transformations\n",
    "visualize_transformations(img, debug_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images(source_dir, target_dir):\n",
    "    \"\"\"\n",
    "    Apply transformations to all images in the specified directory.\n",
    "    The transformed images are saved in a new directory.\n",
    "    \"\"\"\n",
    "    # Get all file names in the source directory\n",
    "    for subfolder in ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']:\n",
    "        source_folder_path = os.path.join(source_dir, subfolder)\n",
    "        filenames = os.listdir(source_folder_path)\n",
    "\n",
    "        # Make the corresponding subfolder in the target directory\n",
    "        target_folder_path = os.path.join(target_dir, subfolder)\n",
    "        os.makedirs(target_folder_path, exist_ok=True)\n",
    "\n",
    "        for filename in filenames:\n",
    "            # Full path to the source file\n",
    "            source_file_path = os.path.join(source_folder_path, filename)\n",
    "\n",
    "            # Read the image\n",
    "            img = cv2.imread(source_file_path)\n",
    "\n",
    "            # If the image was successfully read\n",
    "            if img is not None:\n",
    "                # Apply the transformations (without visualizing)\n",
    "                transformed_img = visualize_transformations(img, debug_mode=False)\n",
    "\n",
    "                # OpenCV uses BGR color format, so we need to convert back from RGB\n",
    "                transformed_img = cv2.cvtColor(transformed_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                # Full path to the target file\n",
    "                target_file_path = os.path.join(target_folder_path, filename)\n",
    "\n",
    "                # Write the transformed image to the target directory\n",
    "                cv2.imwrite(target_file_path, transformed_img)\n",
    "            else:\n",
    "                print(f\"Image {filename} could not be read\")\n",
    "\n",
    "# Paths to the source directories\n",
    "train_dir = os.path.join(src_dir, 'Training')\n",
    "valid_dir = os.path.join(src_dir, 'Testing')\n",
    "\n",
    "# Paths to the target directories\n",
    "cropped_train_dir = os.path.join(src_dir, 'data_cropped', 'Training')\n",
    "cropped_valid_dir = os.path.join(src_dir, 'data_cropped', 'Testing')\n",
    "\n",
    "# Apply the function to each directory\n",
    "process_images(train_dir, cropped_train_dir)\n",
    "process_images(valid_dir, cropped_valid_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first image name from 'yes' directory\n",
    "first_image_name = random.choice(os.listdir(os.path.join(src_dir, 'data_cropped', 'Training', 'glioma_tumor')))\n",
    "\n",
    "# Get full path of the image\n",
    "first_image_path = os.path.join(src_dir, 'data_cropped', 'Training', 'glioma_tumor', first_image_name)\n",
    "\n",
    "# Now read the image\n",
    "img = cv2.imread(first_image_path)\n",
    "\n",
    "# set the paramters we want to change randomly\n",
    "demo_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    brightness_range=[0.1, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "\n",
    "_preview_dir = './data/preview'\n",
    "\n",
    "if os.path.exists(_preview_dir):\n",
    "    print(\"Removing existing directory: 'preview'\")\n",
    "    shutil.rmtree(_preview_dir)\n",
    "os.mkdir(_preview_dir)\n",
    "\n",
    "# load single image for example\n",
    "x = img.reshape((1,) + img.shape) \n",
    "\n",
    "# create directory for augmented images\n",
    "i = 0\n",
    "for batch in demo_datagen.flow(x, batch_size=1, save_to_dir=_preview_dir, save_prefix='aug_img', save_format='jpg'):\n",
    "    i += 1\n",
    "    if i > 20:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,6))\n",
    "i = 1\n",
    "for img in os.listdir(_preview_dir):\n",
    "    img = cv2.imread(os.path.join(_preview_dir, img))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.subplot(3,7,i)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    i += 1\n",
    "    if i > 3*7:\n",
    "        break\n",
    "plt.suptitle('Augemented Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_files(source_dir, target_dir, file_limit=100):\n",
    "    # For each subfolder in the source directory\n",
    "    for subfolder in os.listdir(source_dir):\n",
    "        source_subfolder = os.path.join(source_dir, subfolder)\n",
    "        target_subfolder = os.path.join(target_dir, subfolder)\n",
    "\n",
    "        # Create the corresponding subfolder in the target directory if it doesn't exist\n",
    "        os.makedirs(target_subfolder, exist_ok=True)\n",
    "\n",
    "        # Get a list of file names in the subfolder\n",
    "        filenames = os.listdir(source_subfolder)\n",
    "\n",
    "        # Choose a random sample of files\n",
    "        chosen_files = random.sample(filenames, file_limit)\n",
    "\n",
    "        # For each chosen file\n",
    "        for filename in chosen_files:\n",
    "            # Move the file to the target subfolder\n",
    "            shutil.move(os.path.join(source_subfolder, filename), os.path.join(target_subfolder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = './data/data_cropped/Test'\n",
    "if os.path.exists(test_dir):\n",
    "    print(\"Removing existing directory: 'Test'\")\n",
    "    shutil.rmtree(test_dir)\n",
    "os.mkdir(os.path.join(src_dir, 'data_cropped', 'Test'))\n",
    "\n",
    "# Paths to the source (training) and target (testing) directories\n",
    "train_dir = './data/data_cropped/Training'\n",
    "test_dir = './data/data_cropped/Test'\n",
    "\n",
    "# Move a random sample of 100 files from each subfolder of the training directory to the testing directory\n",
    "move_files(train_dir, test_dir, file_limit=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.efficientnet import EfficientNetB0, preprocess_input\n",
    "\n",
    "TRAIN_DIR = './data/data_cropped/Training'\n",
    "VAL_DIR = './data/data_cropped/Testing'\n",
    "TEST_DIR = './data/data_cropped/Test'\n",
    "IMG_SIZE = (256, 256)\n",
    "CLASS_MODE = 'categorical'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    # rotation_range=15,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    # vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=32,\n",
    "    class_mode=CLASS_MODE,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    color_mode='rgb',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=16,\n",
    "    class_mode=CLASS_MODE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=20,\n",
    "        class_mode=CLASS_MODE,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import efficientnet\n",
    "\n",
    "pre_trained_model = efficientnet.EfficientNetB0(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
    "\n",
    "# Freeze the weights of the layers.\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "myCallback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    mode='min',\n",
    "    patience=6,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_acc', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        pre_trained_model,  # Pretrained base\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hp_units, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_generator, validation_data=validation_generator, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    pre_trained_model,  # Pretrained base\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=100, validation_data=validation_generator, verbose=1, callbacks=[reduce_lr, myCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model performance\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(history.epoch) + 1)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Train Set')\n",
    "plt.plot(epochs_range, val_acc, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Train Set')\n",
    "plt.plot(epochs_range, val_loss, label='Val Set')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval (Val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics2dt(acc, rc, pr, f1):\n",
    "    return pd.DataFrame(data={\"Accuracy\":acc, \"Recall\":rc, \"Precision\":pr, \"F1-Score\":f1}, index=[0])\n",
    "\n",
    "def show_metrics(y_true, y_pred):\n",
    "    recall = tf.keras.metrics.Recall()\n",
    "    precision = tf.keras.metrics.Precision()\n",
    "    accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "    recall.update_state(y_true, y_pred)\n",
    "    recall = recall.result().numpy()\n",
    "    \n",
    "    precision.update_state(y_true, y_pred)\n",
    "    precision = precision.result().numpy()\n",
    "    \n",
    "    accuracy.update_state(y_true, y_pred)\n",
    "    accuracy = accuracy.result().numpy()\n",
    "    \n",
    "    f1_score = 0\n",
    "    if recall+precision != 0:\n",
    "        f1_score = 2 * ((recall*precision)/(recall+precision))\n",
    "    \n",
    "    return metrics2dt(accuracy, recall, precision, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming that you have the true labels\n",
    "true_labels = validation_generator.classes\n",
    "\n",
    "# Get the predicted probabilities from the model\n",
    "predicted_probs = history.model.predict(validation_generator, steps=len(validation_generator))\n",
    "\n",
    "# Convert probabilities to class labels: if you're working on a binary classification problem\n",
    "# predicted_labels = [1 if prob > 0.5 else 0 for prob in predicted_probs]\n",
    "\n",
    "# If you're working on a multi-class classification problem, use argmax\n",
    "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot it using seaborn\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming that you have the true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Get the predicted probabilities from the model\n",
    "predicted_probs = history.model.predict(test_generator, steps=len(test_generator))\n",
    "\n",
    "# Convert probabilities to class labels: if you're working on a binary classification problem\n",
    "# predicted_labels = [1 if prob > 0.5 else 0 for prob in predicted_probs]\n",
    "\n",
    "# If you're working on a multi-class classification problem, use argmax\n",
    "predicted_labels = np.argmax(predicted_probs, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Plot it using seaborn\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metrics(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./output_model/brain_tumor.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
